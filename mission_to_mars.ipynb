{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - There is no [mac64] chromedriver for browser 89.0.4389 in cache\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - Trying to download new driver from https://chromedriver.storage.googleapis.com/89.0.4389.23/chromedriver_mac64.zip\n",
      "[WDM] - Driver has been saved in cache [/Users/franciscozuluaga/.wdm/drivers/chromedriver/mac64/89.0.4389.23]\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visit nasa url\n",
    "nasa_url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "browser.visit(nasa_url)\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape page into soup\n",
    "html= browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the content title and the body article\n",
    "news_title = soup.find_all(class_='content_title')\n",
    "news_article = soup.find_all(class_='article_teaser_body')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#image url\n",
    "featured_image_url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html'\n",
    "image_path = soup.find_all('img')[2][\"src\"]\n",
    "img = featured_image_url + image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MARS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image_url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visit mars url\n",
    "    browser.visit(featured_image_url)\n",
    "    html = browser.html\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a beautifulsoup object so it can be parsed with the html.parser\n",
    "    jpl_image_soup = bs(html, 'html.parser')\n",
    "\n",
    "    #looking for the class in the html called headerimage\n",
    "    featured_image = jpl_image_soup.find_all('img', class_='headerimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop to get the image\n",
    "    for image in featured_image:\n",
    "        featured_image_url = f\"https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/{image['src']}\"\n",
    "    jpl_image_dict = {}\n",
    "    jpl_image_dict['img url'] = featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Mars scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Scraped table containing facts about the planet\n",
    "    mars_url = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Read url and returned a list of DataFrames\n",
    "    mars_table = pd.read_html(mars_url)\n",
    "    mars_table = mars_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Converted data to HTML table string\n",
    "    html_mars_table = mars_table.to_html()\n",
    "    mars_dict = {}\n",
    "    mars_dict['mars table'] = html_mars_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #hempishphere scrape\n",
    "\n",
    "    hemispheres_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #url that is being scraped\n",
    "    browser.visit(hemispheres_url)\n",
    "    html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #creating the beautifulsoup object\n",
    "    soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #finding all instanced of the class called description in the html\n",
    "    names = soup.find_all(class_='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #initlizing hemisphere_list\n",
    "    hemisphere_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #for loop to ge the h3 anchor tags that are stored in the \"names\" variables\n",
    "    for name in names:\n",
    "        hemisphere_list.append(name.a.h3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #go through the pages to get the image info\n",
    "    browser.visit(hemispheres_url)\n",
    "    hemisphere_image_urls=[]\n",
    "    for x in range(len(hemisphere_list)):\n",
    "            html = browser.html\n",
    "            soup = bs(html, 'html.parser')\n",
    "            browser.click_link_by_partial_text(hemisphere_list[i])\n",
    "            html = browser.html\n",
    "            soup = bs(html, 'html.parser')\n",
    "            title = hemisphere_list[i]\n",
    "            img_url = soup.find(class_='downloads')\n",
    "                \n",
    "            hemisphere_dict = {}\n",
    "            hemisphere_dict['title'] = title\n",
    "            hemisphere_dict['img_url'] = img_url.a['href']\n",
    "            hemisphere_image_urls.append(hemisphere_dict)\n",
    "            browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Adding everything into dictionaries/lists\n",
    "    nasa_data = []\n",
    "    nasa_data.append(news_dict)\n",
    "    nasa_data.append(jpl_image_dict)\n",
    "    nasa_data.append(mars_dict)\n",
    "    nasa_data.append(hemisphere_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
